Coding samples from HuggingFace quantization courses.

Finished Courses:
1. _HF Quantization Fundamentals_: [https://www.deeplearning.ai/short-courses/quantization-fundamentals-with-hugging-face/]
- Basic quantization techniques in PyTorch
- PyTorch types (int8, float, bfloat16...) --> review these
- using "quanto"

In-Progress:
1. _HF Quantization in Depth_: [https://www.deeplearning.ai/short-courses/quantization-in-depth/]
- Linear quantization: r = s(q - z); q = int(round(r/s + z))

Next To-Do:
1. [https://medium.com/@sayedebad.777/the-power-of-quantization-in-ml-a-pytorch-tutorial-part-1-8d0c1bf8b679]
2. [https://medium.com/@sayedebad.777/the-power-of-quantization-in-ml-a-pytorch-tutorial-part-2-3557ffb1249f]
3. [https://medium.com/@sayedebad.777/the-power-of-quantization-in-ml-a-pytorch-tutorial-part-3-9b7dba23e067]
4. [https://github.com/intel/neural-compressor/blob/master/docs/source/quantization.md]
5. [https://huggingface.co/docs/transformers/v4.45.2/quantization/overview]
6. [https://pytorch.org/blog/quantization-in-practice/]

AMD Docs:
1. AMD Quark: [https://quar.docs.amd.com]
2. AMD ROCm: [https://rocm.docs.amd.com/en/latest]

Other Docs:
1. PyTorch Quantization: [https://pytorch.org/docs/stable/quantization.html]
2. intel/neural-compressor: [https://github.com/intel/neural-compressor/tree/master]
3. huggingface/optimum-quanto: [https://github.com/huggingface/optimum-quanto]
4. NVIDIA/TensorRT-Model-Optimizer: [https://github.com/NVIDIA/TensorRT-Model-Optimizer/]
5. vllm-project/vllm: [https://github.com/vllm-project/vllm]

Research blogs in similar areas:
- HF blog
- PyTorch blog
- PyTorch dev forum
- NVIDIA blog
- AI research from Intel
- AI research from Qualcomm
